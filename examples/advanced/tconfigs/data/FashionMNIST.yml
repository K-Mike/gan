hparams:
  image_side: &image_side {{ image_side or 28}}
  noise_dim: &noise_dim {{ noise_dim or 128 }}
  batch_size: &batch_size {{ batch_size or 128 }}

runner_params:
  # input keys
  # Note: for albumentations transforms we have to have key "image" =(
  data_input_key: &real_data "image"
  noise_input_key: &noise_input "noise"


stages:

  transform_params:
    transform: A.Compose
    transforms:
      - transform: PillowToNumpy
        image_key: *real_data
        channels: 1
      - transform: A.Normalize
        mean: [0.5]
        std: [0.5]
      - transform: A.ToTensorV2
      - transform: AdditionalNoiseTensor
        tensor_size: [*noise_dim]
        output_key: *noise_input

  data_params:
    batch_size: *batch_size

    datasets:
      train:
        dataset: torchvision.keyvalue.FashionMNIST  # todo: gray image input
        root: ./data/FashionMNIST
        train: True
        download: True
    image_key: *real_data

  state_params:
    valid_loader: "train"